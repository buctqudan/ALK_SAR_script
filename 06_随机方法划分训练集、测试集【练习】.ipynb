{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这部分是随机划分的脚本：如果划分好了就可以不用这个-步骤1\n",
    "from sklearn.model_selection import train_test_split\n",
    "file_name_1= r\"Q:\\ALK_1_Wild\\3.ALK_300nM_RANDOM_ECFP4\\index_ChEMBL_TargetID_CHEMBL4247_1810ECFP4_filter387_1.csv\"\n",
    "X_1 = pd.read_csv(file_name_1).iloc[:,:-2]\n",
    "y_1 = pd.read_csv(file_name_1).iloc[:,-2]\n",
    "last_col_1 = pd.read_csv(file_name_1).iloc[:, -1]\n",
    "# tr_x_1,te_x_1,tr_y_1,te_y_1 = train_test_split(X_1,y_1,test_size=0.33,random_state=111)\n",
    "tr_x_1,te_x_1,tr_y_1,te_y_1,tr_last_col_1,te_last_col_1 = train_test_split(X_1, y_1, last_col_1, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这部分是随机划分的脚本：如果划分好了就可以不用这个-步骤2\n",
    "from sklearn.model_selection import train_test_split\n",
    "file_name_0 = r\"Q:\\ALK_1_Wild\\3.ALK_300nM_RANDOM_ECFP4\\index_ChEMBL_TargetID_CHEMBL4247_1810ECFP4_filter387_0.csv\"\n",
    "X_0 = pd.read_csv(file_name_0).iloc[:,:-2]\n",
    "y_0 = pd.read_csv(file_name_0).iloc[:,-2]\n",
    "last_col_0 = pd.read_csv(file_name_0).iloc[:, -1]\n",
    "# tr_x_0,te_x_0,tr_y_0,te_y_0 = train_test_split(X_0,y_0,test_size=0.33,random_state=111)\n",
    "tr_x_0,te_x_0,tr_y_0,te_y_0,tr_last_col_0,te_last_col_0 = train_test_split(X_0, y_0, last_col_0, test_size=0.33, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这部分是随机划分的脚本：如果划分好了就可以不用这个-步骤3\n",
    "tr_x = pd.concat((tr_x_1,tr_x_0),axis = 0)\n",
    "tr_y = pd.concat((tr_y_1,tr_y_0),axis = 0)\n",
    "te_x = pd.concat((te_x_1,te_x_0),axis = 0)\n",
    "te_y = pd.concat((te_y_1,te_y_0),axis = 0)\n",
    "tr_last_col = pd.concat((tr_last_col_1, tr_last_col_0), axis=0)\n",
    "te_last_col = pd.concat((te_last_col_1, te_last_col_0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并特征列、目标列和最后一列\n",
    "tr_data = pd.concat([tr_x, tr_y, tr_last_col], axis=1)\n",
    "te_data = pd.concat([te_x, te_y, te_last_col], axis=1)\n",
    "\n",
    "# 保存为新的CSV文件\n",
    "train_output_file_path = file_name_1[:-6] + '-ran-111' + '_tr_%d.csv' % len(tr_x)\n",
    "test_output_file_path = file_name_1[:-6] + '-ran-111' + '_te_%d.csv' % len(te_x)\n",
    "\n",
    "tr_data.to_csv(train_output_file_path, index=False)\n",
    "te_data.to_csv(test_output_file_path, index=False)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Training Data saved to:\", train_output_file_path)\n",
    "print(\"Testing Data saved to:\", test_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这部分是随机划分的脚本：如果划分好了就可以不用这个-步骤5\n",
    "tr_x = tr_data.iloc[:,:-2]\n",
    "te_X = te_data.iloc[:,:-2]\n",
    "tr_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
